{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "nMC = 1000 #number of runs for MC simulation\n",
    "r20 = np.array([iter_i_error(.2) for i in range(nMC)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean and sd of dper_err,mice_err, soft_err, resi_err, missf_err at 20% missing rate\n",
      "[0.1059875  0.10737083 0.10949583 0.69689167 0.10698333]\n",
      "[0.0202579  0.02035946 0.02060085 0.1575932  0.02073938]\n"
     ]
    }
   ],
   "source": [
    "    m20 = np.array([np.mean(r20[:,i]) for i in range(5)])\n",
    "    s20 = np.array([np.std(r20[:,i]) for i in range(5)])\n",
    "    print('mean and sd of dper_err,mice_err, soft_err, resi_err, missf_err at 20% missing rate')\n",
    "    print(m20)\n",
    "    print(s20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "nMC = 1000 #number of runs for MC simulation\n",
    "r35 = np.array([iter_i_error(.35) for i in range(nMC)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean and sd of dper_err,mice_err, soft_err, resi_err, missf_err at 35% missing rate\n",
      "[0.10805417 0.11207917 0.11342083 0.7158625  0.11015417]\n",
      "[0.02060395 0.02124052 0.02148569 0.14258195 0.02108351]\n"
     ]
    }
   ],
   "source": [
    "    m35 = np.array([np.mean(r35[:,i]) for i in range(5)])\n",
    "    s35 = np.array([np.std(r35[:,i]) for i in range(5)])\n",
    "    print('mean and sd of dper_err,mice_err, soft_err, resi_err, missf_err at 35% missing rate')\n",
    "    print(m35)\n",
    "    print(s35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "nMC = 1000 #number of runs for MC simulation\n",
    "r50 = np.array([iter_i_error(.5) for i in range(nMC)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean and sd of dper_err,mice_err, soft_err, resi_err, missf_err at 50% missing rate\n",
      "[0.11007083 0.12112917 0.1173625  0.71365417 0.11348333]\n",
      "[0.02058734 0.02379089 0.02234402 0.15076692 0.02186301]\n"
     ]
    }
   ],
   "source": [
    "    m50 = np.array([np.mean(r50[:,i]) for i in range(5)])\n",
    "    s50 = np.array([np.std(r50[:,i]) for i in range(5)])\n",
    "    print('mean and sd of dper_err,mice_err, soft_err, resi_err, missf_err at 50% missing rate')\n",
    "    print(m50)\n",
    "    print(s50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "nMC = 1000 #number of runs for MC simulation\n",
    "r65 = np.array([iter_i_error(.65) for i in range(nMC)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean and sd of dper_err,mice_err, soft_err, resi_err, missf_err at 65% missing rate\n",
      "[0.11339167 0.13123333 0.12140417 0.70807083 0.11779167]\n",
      "[0.02230634 0.02836517 0.02319985 0.14835048 0.02259744]\n"
     ]
    }
   ],
   "source": [
    "    m65 = np.array([np.mean(r65[:,i]) for i in range(5)])\n",
    "    s65 = np.array([np.std(r65[:,i]) for i in range(5)])\n",
    "    print('mean and sd of dper_err,mice_err, soft_err, resi_err, missf_err at 65% missing rate')\n",
    "    print(m65)\n",
    "    print(s65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "nMC = 1000 #number of runs for MC simulation\n",
    "r80 = np.array([iter_i_error(.8) for i in range(nMC)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean and sd of dper_err,mice_err, soft_err, resi_err, missf_err at 80% missing rate\n",
      "[0.12845417 0.15279167 0.12769583 0.7107625  0.12581667]\n",
      "[0.07751476 0.04150617 0.02571019 0.12895851 0.02618629]\n"
     ]
    }
   ],
   "source": [
    "    m80 = np.array([np.mean(r80[:,i]) for i in range(5)])\n",
    "    s80 = np.array([np.std(r80[:,i]) for i in range(5)])\n",
    "    print('mean and sd of dper_err,mice_err, soft_err, resi_err, missf_err at 80% missing rate')\n",
    "    print(m80)\n",
    "    print(s80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.106, 0.107, 0.109, 0.697, 0.107],\n",
       "       [0.108, 0.112, 0.113, 0.716, 0.11 ],\n",
       "       [0.11 , 0.121, 0.117, 0.714, 0.113],\n",
       "       [0.113, 0.131, 0.121, 0.708, 0.118],\n",
       "       [0.128, 0.153, 0.128, 0.711, 0.126]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_assume_equal_cov_err = np.vstack((m20,m35,m50,m65,m80))\n",
    "not_assume_equal_cov_err.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01Q1wGI3uIdg"
   },
   "source": [
    "## libraries and function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import math    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    def iter_i_error(missing_rate):   \n",
    "         G, n_per_class = 4, 120\n",
    "         mul = 2\n",
    "         mu_1, mu_2 = mul*np.array([1,-1]), mul*np.array([1,1])\n",
    "         mu_3, mu_4 = mul*np.array([-1,-1]), mul*np.array([-1,1])\n",
    "         S_1, S_2 = np.array([[2,.7],[.7,2]]), np.array([[1.5,.5],[.5,1.5]])\n",
    "         S_3, S_4 = np.array([[2,.9],[.9,2]]), np.array([[1.5,.7],[.7,1.5]])\n",
    "         X_1 = np.random.multivariate_normal(mu_1,S_1,n_per_class)\n",
    "         X_2 = np.random.multivariate_normal(mu_2,S_2,n_per_class)\n",
    "         X_3 = np.random.multivariate_normal(mu_3,S_3,n_per_class)\n",
    "         X_4 = np.random.multivariate_normal(mu_4,S_4,n_per_class)        \n",
    "         X = np.vstack((X_1,X_2, X_3, X_4))\n",
    "         y = np.hstack((np.repeat(0,n_per_class), np.repeat(1,n_per_class), \n",
    "                        np.repeat(2,n_per_class),np.repeat(3,n_per_class)))   \n",
    "         Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.5)        \n",
    "         \n",
    "         dper_err = compute_err_MLE(Xtrain, ytrain, Xtest, ytest, G, missing_rate)\n",
    "         mice_err = compute_err_mice(Xtrain, ytrain, Xtest, ytest, G, missing_rate)\n",
    "         soft_err = compute_err_SOFT(Xtrain, ytrain, Xtest, ytest, G, missing_rate);\n",
    "         missf_err = compute_err_MissF(Xtrain, ytrain, Xtest, ytest, G, missing_rate);\n",
    "         resi_err = compute_err_resi(Xtrain, ytrain, Xtest, ytest, G, missing_rate)\n",
    "         return np.hstack((dper_err,mice_err, soft_err, resi_err, missf_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27823,
     "status": "ok",
     "timestamp": 1632813901150,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": -120
    },
    "id": "iEdO9dJPION8",
    "outputId": "ac381831-0e95-4c42-a071-43700bc50032"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn case importing missingpy result in the error\\n\"No module named \\'sklearn.neighbors._base\\'\"\\nThen run the following\\nimport sklearn.neighbors._base\\nimport sys\\nsys.modules[\\'sklearn.neighbors.base\\'] = sklearn.neighbors._base\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install impyute\n",
    "# !pip install fancyimpute\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "# import impyute as impy\n",
    "from fancyimpute import SoftImpute\n",
    "import pandas as pd\n",
    "import time\n",
    "# !pip install missingpy\n",
    "import sklearn.neighbors._base\n",
    "import sys\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "from missingpy import MissForest\n",
    "'''\n",
    "In case importing missingpy result in the error\n",
    "\"No module named 'sklearn.neighbors._base'\"\n",
    "Then run the following\n",
    "import sklearn.neighbors._base\n",
    "import sys\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1632813901422,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": -120
    },
    "id": "xiZ7C5gU2ywr"
   },
   "outputs": [],
   "source": [
    "def diag_term(X,i):\n",
    "  arr0 = X[:,i].flatten()\n",
    "  arr = arr0[~np.isnan(arr0)]\n",
    "  return np.var(arr)\n",
    "\n",
    "def musMLE(X,y,G):\n",
    "    n,p = X.shape[0], X.shape[1]\n",
    "    f = lambda g: np.nanmean(X[y==g,:],axis=0)\n",
    "    musMLE = np.array([f(g) for g in range(G)])    \n",
    "    return musMLE.T\n",
    "\n",
    "def Smle(X,y,musMLE,g):\n",
    "    '''\n",
    "    function to compute the covariance matrix for the g-th class\n",
    "    X: input, should be a numpy array\n",
    "    y: label\n",
    "    G: number of classes\n",
    "    g: class index\n",
    "    output:\n",
    "    - mus: each row is a class mean\n",
    "    - S: common covariance matrix of class 1,2,..., G \n",
    "    '''\n",
    "    epsilon = 1e-5 # define epsilon to put r down to 0 if r < epsilon\n",
    "    Xg, yg = X[y==g,:], y[y==g]\n",
    "    n,p = Xg.shape[0], Xg.shape[1] \n",
    " \n",
    "    S = np.diag([diag_term(Xg,i) for i in range(p)]) \n",
    "\n",
    "    for i in range(p):      \n",
    "      for j in range(i):\n",
    "        if ((S[i,i] == 0.) | (S[j,j] == 0.)):\n",
    "          S[i,j] = S[j,i] = 0.\n",
    "          continue\n",
    "\n",
    "        mat = Xg[:,[i,j]]\n",
    "\n",
    "        # drop rows with NA\n",
    "        idx = ~np.isnan(mat).any(axis=1)\n",
    "        mat, y_arr = mat[idx], yg[idx]\n",
    "        A = mg = len(y_arr) \n",
    "\n",
    "        s11 = mg*np.var(mat[:,0])\n",
    "        s22 = mg*np.var(mat[:,1])\n",
    "        s12 = sum((mat[:,0]-musMLE[i,g])*(mat[:,1]-musMLE[j,g]))\n",
    "        B = S[i,i]*S[j,j]*A - s22 * S[i,i] - s11 * S[j,j]\n",
    "        coefficient = [-A, s12, B, s12*S[i,i]*S[j,j]]\n",
    "        r = np.roots(coefficient)\n",
    "        r = r[abs(np.imag(r)) < epsilon]\n",
    "        r = np.real(r)\n",
    "        r[abs(r) < epsilon] = 0\n",
    " \n",
    "        if len(r)>1:\n",
    "          condi_var = S[j,j] - r**2/S[i,i]\n",
    "          eta = -A*np.log(condi_var)-(S[j,j]-2*r/S[i,i]*s12 + r**2/S[i,i]**2*s11)/condi_var\n",
    "          r = r[eta == max(eta[~np.isnan(eta)])]\n",
    "\n",
    "        if len(r) > 1: \n",
    "          if sum(r==0.0) == len(r):\n",
    "            r = 0.\n",
    "          else:  \n",
    "            w = np.cov(mat, rowvar=False)  \n",
    "            #r = r[w[0,1]*r>=0]\n",
    "            r = r[np.abs(r-w[0,1]).argmin()] # select r that is closet to w[0,1] \n",
    "\n",
    "        S[i,j] = S[j,i] = r\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1632813901423,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": -120
    },
    "id": "QBDnkPj8SAdp"
   },
   "outputs": [],
   "source": [
    "def generate_nan(Xtrain, missing_rate):\n",
    "  Xshape = Xtrain.shape\n",
    "  na_id = np.random.randint(0,Xtrain.size,round(missing_rate*Xtrain.size))\n",
    "  Xtr_nan = Xtrain.flatten()\n",
    "  Xtr_nan[na_id] = np.nan \n",
    "  return Xtr_nan.reshape(Xshape) \n",
    "def qda_miss(mus, S, Xtest, ytrain, ytest, G):\n",
    "#         mus: each row is a class mean\n",
    "# S: the ith component is the covariance matrix of the g^th class\n",
    "    pi = np.array([np.sum(ytrain==i) for i in range(G)])/len(ytrain) #vector of prior probabilities\n",
    "    f = lambda g: np.log(pi[g]) - np.log(np.linalg.det(S[g]))/2\n",
    "#     print(pi)\n",
    "    class_terms = [f(g) for g in np.arange(G)]\n",
    "#     print(class_terms)\n",
    "#     print(np.array([np.linalg.det(S[g]) for g in range(G)]))\n",
    "    \n",
    "    h = lambda g,i: class_terms[g] - np.matmul((Xtest[i,:]-mus[:,g]).T, np.matmul(\n",
    "                    np.linalg.inv(S[g]), (Xtest[i,:]-mus[:,g]).T))/2\n",
    "    pred_label = [np.argmax([h(g,i) for g in np.arange(G)]) \n",
    "                  for i in np.arange(len(Xtest))]\n",
    "    pred_label = np.asarray(pred_label)\n",
    "    return np.mean(pred_label.flatten() != ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1632813901424,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": -120
    },
    "id": "3phgXywFRbWQ"
   },
   "outputs": [],
   "source": [
    "def compute_err_MLE(Xtrain, ytrain, Xtest, ytest, G, missing_rate):    \n",
    "    # missing_rate: missing rate on training set\n",
    "    Xtr_nan,ytrain = generate_nan(Xtrain,ytrain, missing_rate)\n",
    "    scaler = StandardScaler() \n",
    "    scaler.fit(Xtr_nan)\n",
    "    Xtr_nan = scaler.transform(Xtr_nan)\n",
    "    Xtest = scaler.transform(Xtest)\n",
    "    \n",
    "    Xtrain = scaler.transform(Xtrain)\n",
    "    # MLEs approach\n",
    "    start = time.time()\n",
    "    mus_mle = musMLE(Xtr_nan,ytrain,G)\n",
    "    S_mle = np.array([Smle(Xtr_nan,ytrain,mus_mle, g) for g in range(G)])   \n",
    "    mle_err = qda_miss(mus_mle, S_mle, Xtest, ytrain, ytest, G)\n",
    "    mle_time = time.time()-start\n",
    "    return mle_err#, mle_time\n",
    "    \n",
    "def compute_err_SOFT(Xtrain, ytrain, Xtest, ytest, G, missing_rate):    \n",
    "    # missing_rate: missing rate on training set\n",
    "    Xtr_nan, ytrain = generate_nan(Xtrain, ytrain, missing_rate)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(Xtr_nan)\n",
    "    Xtr_nan = scaler.transform(Xtr_nan)\n",
    "    Xtest = scaler.transform(Xtest)\n",
    "\n",
    "    start = time.time()\n",
    "#     Xtr_softimpute = SoftImpute(max_iters = 100).fit_transform(Xtr_nan)\n",
    "    Xtr_missf = np.array([SoftImpute(max_iters = 100, verbose = False).fit_transform(Xtr_nan[ytrain==g]) for g in range(G)])\n",
    "    Xtr_missf = np.concatenate(Xtr_missf, axis = 0)\n",
    "    ytrain = np.array([np.repeat(g, sum(ytrain==g)) for g in range(G)])\n",
    "    ytrain = np.concatenate(ytrain, axis = 0)\n",
    "    clf_softimpute = QuadraticDiscriminantAnalysis().fit(Xtr_missf, ytrain)\n",
    "    softimpute_err = np.mean(clf_softimpute.predict(Xtest).flatten() != ytest)\n",
    "    softimpute_time = time.time()-start\n",
    "\n",
    "    return softimpute_err#, softimpute_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1632813901425,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": -120
    },
    "id": "H73Ts-mmS12a"
   },
   "outputs": [],
   "source": [
    "def compute_err_MissF(Xtrain, ytrain, Xtest, ytest, G, missing_rate):    \n",
    "    # missing_rate: missing rate on training set\n",
    "    Xtr_nan, ytrain = generate_nan(Xtrain, ytrain, missing_rate)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(Xtr_nan)\n",
    "    Xtr_nan = scaler.transform(Xtr_nan)\n",
    "    Xtest = scaler.transform(Xtest)\n",
    "    \n",
    "    start = time.time()\n",
    "#     Xtr_missf = MissForest(random_state=0).fit_transform(Xtr_nan)\n",
    "    Xtr_missf = np.array([MissForest(random_state=0, verbose = False).fit_transform(Xtr_nan[ytrain==g]) for g in range(G)])\n",
    "    Xtr_missf = np.concatenate(Xtr_missf, axis = 0)\n",
    "    ytrain = np.array([np.repeat(g, sum(ytrain==g)) for g in range(G)])\n",
    "    ytrain = np.concatenate(ytrain, axis = 0)\n",
    "    clf_missf = QuadraticDiscriminantAnalysis().fit(Xtr_missf, ytrain)\n",
    "    missf_err = np.mean(clf_missf.predict(Xtest).flatten() != ytest)\n",
    "    missf_time = time.time()-start\n",
    "\n",
    "    return missf_err#, missf_time\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "def compute_err_mice(Xtrain, ytrain, Xtest, ytest, G, missing_rate):    \n",
    "    # missing_rate: missing rate on training set\n",
    "    Xtr_nan, ytrain = generate_nan(Xtrain, ytrain, missing_rate)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(Xtr_nan)\n",
    "    Xtr_nan = scaler.transform(Xtr_nan)\n",
    "    Xtest = scaler.transform(Xtest)\n",
    "\n",
    "    start = time.time()\n",
    "#     Xtr_mice= IterativeImputer(max_iter=100).fit(Xtr_nan).transform(Xtr_nan)\n",
    "    Xtr_missf = np.array([ IterativeImputer(max_iter=100).fit_transform(Xtr_nan[ytrain==g]) for g in range(G)])\n",
    "    Xtr_mice = np.concatenate(Xtr_missf, axis = 0)\n",
    "    ytrain = np.array([np.repeat(g, sum(ytrain==g)) for g in range(G)])\n",
    "    ytrain = np.concatenate(ytrain, axis = 0)\n",
    "    clf_mice= QuadraticDiscriminantAnalysis().fit(Xtr_mice, ytrain)\n",
    "    mice_err = np.mean(clf_mice.predict(Xtest).flatten() != ytest)\n",
    "    mice_time = time.time()-start\n",
    "\n",
    "    return mice_err#, mice_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attribute_weights(A):\n",
    "  from sklearn.preprocessing import minmax_scale\n",
    "  y = minmax_scale(A, axis = 0)\n",
    "  p = y.copy()\n",
    "  ysum = y.sum(axis = 0)\n",
    "  for i in range(y.shape[1]):\n",
    "    if (ysum[i] == 0):\n",
    "      p[:, i] = 1\n",
    "    else:\n",
    "      p[:, i] = y[:, i] / ysum[i]\n",
    "  from scipy.special import xlogy\n",
    "  E = - xlogy(p,p).sum(axis=0) / math.log(p.shape[0])\n",
    "  w = (1 - E)/(len(E) - E.sum())\n",
    "  if np.isnan(w).any():\n",
    "    return None\n",
    "  else:\n",
    "    return w                                            \n",
    "def generate_tuple_partition(CT, ICT, m):\n",
    "  w = compute_attribute_weights(CT)\n",
    "  r = np.ones(ICT.shape[0])\n",
    "  for i in range(ICT.shape[0]):\n",
    "    for j in range(ICT.shape[1]):\n",
    "      if np.isnan(ICT[i,j]):\n",
    "        r[i] -= w[j] #If NoneType then insufficient CT set has been used\n",
    "  ICT = ICT[r.argsort()[::-1],:]\n",
    "  return np.array_split(ICT, m)\n",
    "def resi(Xtr_nan, m, n_neighbors):\n",
    "  CT = [Xtr_nan[~np.isnan(Xtr_nan).any(axis=1)]]\n",
    "  Tp = []\n",
    "  T = generate_tuple_partition(CT[0],Xtr_nan[np.isnan(Xtr_nan).any(axis=1)], m)\n",
    "  from sklearn.impute import KNNImputer\n",
    "  for i in range(m):\n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "    imputer.fit(CT[-1])\n",
    "    Tp.append(imputer.transform(T[i]))\n",
    "    CT.append(np.concatenate((CT[-1],Tp[-1])))\n",
    "  Tpp = []\n",
    "  for i in range(m):\n",
    "    train = CT[0]\n",
    "    for j in range(1,m):\n",
    "      if j != i:\n",
    "        train = np.concatenate((train,T[j]))\n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "    imputer.fit(train)\n",
    "    Tpp.append(imputer.transform(T[i]))\n",
    "  imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "  imputer.fit(CT[0])\n",
    "  Tpp.append(imputer.transform(T[m-1]))\n",
    "  CT = [CT[0]]\n",
    "  for i in range(m):\n",
    "    CT.append(np.concatenate((CT[-1],np.mean(np.array([Tp[i], Tpp[i]]), axis=0 ))))\n",
    "  return CT[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nan(Xtrain,ytr, missing_rate):\n",
    "  minimum_complete_samples = 3\n",
    "  ct_id = np.random.choice(range(Xtrain.shape[0]), size = minimum_complete_samples, replace = False)\n",
    "  CT = Xtrain[ct_id]\n",
    "  ICT = Xtrain[[i for i in range(Xtrain.shape[0]) if i not in ct_id]]\n",
    "  ICTshape = ICT.shape\n",
    "  na_id = np.random.randint(0,ICT.size, round(missing_rate*ICT.size))\n",
    "  ICT = ICT.flatten()\n",
    "  ICT[na_id] = np.nan\n",
    "  xxx = np.concatenate((CT,ICT.reshape(ICTshape)))\n",
    "  ytrain = np.hstack((ytr[ct_id], np.array([ytr[i] for i in range(Xtrain.shape[0]) if i not in ct_id])))\n",
    "  return xxx, ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def compute_err_resi(Xtrain, ytrain, Xtest, ytest, G, missing_rate):    \n",
    "        # missing_rate: missing rate on training set\n",
    "        Xtr_nan, ytrain = generate_nan(Xtrain,ytrain, missing_rate)\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(Xtr_nan)\n",
    "        Xtr_nan = scaler.transform(Xtr_nan)\n",
    "        Xtest = scaler.transform(Xtest)\n",
    "    \n",
    "        start = time.time()\n",
    "        Xtr_resi = resi(Xtr_nan, 3, 3) #Parameters: (Dataset, m, n_neighbors) \n",
    "        clf_resi= QuadraticDiscriminantAnalysis().fit(Xtr_resi, ytrain)\n",
    "        resi_err = np.mean(clf_resi.predict(Xtest).flatten() != ytest)\n",
    "        resi_time = time.time()-start\n",
    "    \n",
    "        return resi_err#, mice_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Not assume equal cov Digits Dper- mice - soft impute.ipynb",
   "provenance": [
    {
     "file_id": "1xKp_k9_rmArWqT_UcIFBuWukG_jHnCVY",
     "timestamp": 1613916983415
    },
    {
     "file_id": "1eazQvNk_WLTaG8heDoHQ3AgEg59y9f0v",
     "timestamp": 1608824112061
    },
    {
     "file_id": "126-leKywWg1oVxbfuH1_ORl8UMYHusn_",
     "timestamp": 1591364956450
    },
    {
     "file_id": "1Lb-WwE7STckIojvf1h3ADYX29-gfA6u-",
     "timestamp": 1590379038322
    },
    {
     "file_id": "1CnbOqwmJydQa8uCCpIR6HRVxw0YnveIP",
     "timestamp": 1590113304994
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
