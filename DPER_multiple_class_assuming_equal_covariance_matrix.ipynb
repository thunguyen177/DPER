{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DPER multiple class assuming equal covariance matrix.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thunguyen177/DPER/blob/main/DPER_multiple_class_assuming_equal_covariance_matrix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01Q1wGI3uIdg"
      },
      "source": [
        "## libraries and function \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEdO9dJPION8"
      },
      "source": [
        "!pip install impyute\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "import impyute as impy\n",
        "from fancyimpute import IterativeSVD, SoftImpute, NuclearNormMinimization\n",
        "import pandas as pd\n",
        "import time\n",
        "!pip install missingpy\n",
        "from missingpy import MissForest\n",
        "# note that MissForest uses sklearn.__version__ 0.22.2.post1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm5CldkaaZWo"
      },
      "source": [
        "## MLE estimation function  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2pnqBY91dul"
      },
      "source": [
        "def diag_term(i,X,y):\n",
        "  arr0 = X[:,i]\n",
        "  nar2 = 0\n",
        "  arr = arr0[~np.isnan(arr0)]\n",
        "  y_arr = y[~np.isnan(arr0)]\n",
        "\n",
        "  _, counts = np.unique(y_arr, return_counts=True)\n",
        "  ind = np.insert(np.cumsum(counts), 0, 0)\n",
        "  \n",
        "  return sum([(ind[g]-ind[g-1])*np.var(arr[ind[g-1]:ind[g]]) for \n",
        "                       g in range(1,G+1)])/len(y_arr)                       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7A2gflMad84"
      },
      "source": [
        "def mle(X,y,G):\n",
        "    '''\n",
        "    X: input, should be a numpy array\n",
        "    y: label\n",
        "    G: number of classes\n",
        "    output:\n",
        "    - mus: each row is a class mean\n",
        "    - S: common covariance matrix of class 1,2,..., G \n",
        "    '''\n",
        "    epsilon = 1e-5 # define epsilon to put r down to 0 if r < epsilon\n",
        "    n,p = X.shape[0], X.shape[1]\n",
        "\n",
        "    # Estimating class means\n",
        "    mus = np.array([np.nanmean(X[y==g,:],axis=0) for g in range (G)]).T # so that each column is the mean of a class\n",
        " \n",
        "    S = np.diag([diag_term(i,X,y) for i in range(p)]) \n",
        "\n",
        "    for i in range(p):      \n",
        "      for j in range(i):\n",
        "        mat = X[:,[i,j]]\n",
        "\n",
        "        # drop rows with NA\n",
        "        idx = ~np.isnan(mat).any(axis=1)\n",
        "        mat, y_arr = mat[idx], y[idx]\n",
        "\n",
        "        _, counts = np.unique(y_arr, return_counts=True)\n",
        "        ind = np.insert(np.cumsum(counts), 0, 0)\n",
        "\n",
        "        m_g = counts\n",
        " \n",
        "        A = len(y_arr) \n",
        "        scaled_mat = [mat[ind[g-1]:ind[g],:]-mus[[i,j],g-1] for g in range(1,G+1)]   \n",
        "\n",
        "        q = lambda g: np.dot(scaled_mat[g][:,0],scaled_mat[g][:,0])\n",
        "        s11 = sum(map(q,range(G))) \n",
        "        q = lambda g: np.dot(scaled_mat[g][:,1],scaled_mat[g][:,1])\n",
        "        s22 = sum(map(q,range(G))) \n",
        "        d = lambda g: np.dot(scaled_mat[g][:,0],scaled_mat[g][:,1])\n",
        "        s12 = sum(map(d,range(G)))  \n",
        "\n",
        "        start_solve = time.time()\n",
        "        B = S[i,i]*S[j,j]*A - s22 * S[i,i] - s11 * S[j,j]\n",
        "        coefficient = [-A, s12, B, s12*S[i,i]*S[j,j]]\n",
        "        r = np.roots(coefficient)\n",
        "\n",
        "        r = r[abs(np.imag(r)) < epsilon]\n",
        "        r = np.real(r)\n",
        "        r[abs(r) < epsilon] = 0\n",
        "\n",
        "        if len(r)>1:\n",
        "          condi_var = S[j,j] - r**2/S[i,i]\n",
        "          eta = -A*np.log(condi_var)-(S[j,j]-2*r/S[i,i]*s12 +\n",
        "                                      r**2/S[i,i]**2*s11)/condi_var\n",
        "          # if condi_var <0 then eta = NA. in practice, it's impossible for cov to be negative\n",
        "          #  therefore, we drop NA elements of eta  \n",
        "          r = r[eta == max(eta[~np.isnan(eta)])]\n",
        "\n",
        "        if len(r) > 1:        \n",
        "            w = [m_g[g-1]*np.cov(mat[ind[g-1]:ind[g],], rowvar=False) for\n",
        "                 g in range(1,G+1)]\n",
        "            w = np.sum(w, axis = 0)    \n",
        "            r = r[np.abs(r-w[0,1]).argmin()] # select r that is closet to w[0,1] \n",
        "              \n",
        "        S[i,j] = S[j,i] = r\n",
        "    return [mus, S]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwG2bsDOOxls"
      },
      "source": [
        "### compute_err function \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEAkkeS5IOOo"
      },
      "source": [
        "def err(mus, S, mus_est, S_est):\n",
        "  er = [np.linalg.norm(mus_est-mus)/mus.size,\n",
        "         np.linalg.norm(S_est.flatten()-S.flatten())/S.size]\n",
        "  return np.mean(er)  \n",
        "\n",
        "def generate_nan(Xtrain, missing_rate):\n",
        "  Xshape = Xtrain.shape\n",
        "  na_id = np.random.randint(0,Xtrain.size,round(missing_rate*Xtrain.size))\n",
        "  Xtr_nan = Xtrain.flatten()\n",
        "  Xtr_nan[na_id] = np.nan \n",
        "  return Xtr_nan.reshape(Xshape)\n",
        "\n",
        "def compute_err(Xtrain, ytrain, G, missing_rate):  \n",
        "    Xtr_nan = generate_nan(Xtrain, missing_rate)\n",
        "    \n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(Xtr_nan)\n",
        "    Xtr_nan = scaler.transform(Xtr_nan)\n",
        "    Xtrain = scaler.transform(Xtrain)\n",
        "    \n",
        "    # estimate parameters from full data\n",
        "    mus = [np.mean(Xtrain[ytrain==g,:], axis=0) for g in np.arange(G)]\n",
        "    mus = np.asarray(mus) # each row is a mean of a class\n",
        "    S = [sum(ytrain==g)*np.cov(Xtrain[ytrain==g,:],rowvar =False) \n",
        "             for g in np.arange(G)]\n",
        "    S = np.sum(S, axis = 0)/len(ytrain)\n",
        "\n",
        "    # MLEs approach\n",
        "    start = time.time()\n",
        "    mus_mle, S_mle = mle(Xtr_nan,ytrain, G)\n",
        "    mle_err = err(mus, S, mus_mle.T, S_mle)\n",
        "    mle_time = time.time()-start\n",
        "\n",
        "    start = time.time()\n",
        "    Xtr_softimpute = SoftImpute(max_iters = 100).fit_transform(Xtr_nan)\n",
        "    mus_softimpute = np.asarray([np.mean(Xtr_softimpute[ytrain==g,:], axis=0\n",
        "                                         ) for g in np.arange(G)])\n",
        "    S_softimpute = np.asarray([(sum(ytrain==g))*np.cov(Xtr_softimpute[ytrain==g,:], rowvar =False) \n",
        "             for g in np.arange(G)])\n",
        "    S_softimpute = np.sum(S_softimpute, axis = 0)/len(ytrain) \n",
        "    softimpute_err =  err(mus, S, mus_softimpute, S_softimpute)\n",
        "    softimpute_time = time.time()-start\n",
        "\n",
        "    start = time.time()\n",
        "    Xtr_mice = IterativeImputer(max_iter=100).fit(Xtr_nan).transform(Xtr_nan)\n",
        "    mus_mice = np.asarray([np.mean(Xtr_mice[ytrain==g,:], axis=0\n",
        "                                   ) for g in np.arange(G)])\n",
        "    S_mice = np.asarray([(sum(ytrain==g))*np.cov(Xtr_mice[ytrain==g,:], rowvar =False) \n",
        "             for g in np.arange(G)])\n",
        "    S_mice = np.sum(S_mice, axis = 0)/len(ytrain) \n",
        "    mice_err = err(mus, S, mus_mice, S_mice)\n",
        "    mice_time = time.time()-start\n",
        "\n",
        "    start = time.time()\n",
        "    Xtr_nuclear = NuclearNormMinimization(max_iters=100).fit_transform(Xtr_nan)\n",
        "    mus_nuclear = np.asarray([np.mean(Xtr_nuclear[ytrain==g,:], axis=0\n",
        "                                      ) for g in np.arange(G)])\n",
        "    S_nuclear = np.asarray([(sum(ytrain==g))*np.cov(Xtr_nuclear[ytrain==g,:], rowvar =False) \n",
        "             for g in np.arange(G)])\n",
        "    S_nuclear = np.sum(S_nuclear, axis = 0)/len(ytrain)\n",
        "    nuclear_err = err(mus, S, mus_nuclear, S_nuclear)\n",
        "    nuclear_time = time.time()-start \n",
        "\n",
        "    start = time.time()\n",
        "    Xtr_mforest = MissForest(random_state=0).fit_transform(Xtr_nan)\n",
        "    mus_mforest = np.asarray([np.mean(Xtr_mforest[ytrain==g,:], axis=0\n",
        "                                      ) for g in np.arange(G)])\n",
        "    S_mforest = np.asarray([(sum(ytrain==g))*np.cov(Xtr_mforest[ytrain==g,:], rowvar =False) \n",
        "             for g in np.arange(G)])\n",
        "    S_mforest = np.sum(S_mforest, axis = 0)/len(ytrain)\n",
        "    mforest_err = err(mus, S, mus_mforest, S_mforest)\n",
        "    mforest_time = time.time()-start      \n",
        "\n",
        "    err_rate = np.vstack((mle_err, mice_err, softimpute_err,nuclear_err,mforest_err))\n",
        "    # running_time = np.array([mle_time, knn_time,mice_time,\n",
        "    #                          softimpute_time,em_time, nuclear_time,\n",
        "    #                         ])    \n",
        "    return err_rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAz9dbKRRcRb"
      },
      "source": [
        "\n",
        "## Inosphere"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJBwudfzRoHp",
        "outputId": "74ebe587-8d3b-4371-caa6-1a61a121452e"
      },
      "source": [
        "data = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data',\n",
        "                  sep = \",\", header = None)\n",
        "# print(data.head())\n",
        "data = pd.DataFrame.to_numpy(data)\n",
        "X, y = data[:,:34].astype(np.float64), data[:,34]\n",
        "le2 = LabelEncoder()\n",
        "y = le2.fit_transform(y)\n",
        "print(len(y))\n",
        "X = np.delete(X,[0,1], axis = 1)\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "351\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(351, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiOEC7k0iWyM"
      },
      "source": [
        "G = 2\n",
        "np.random.seed(8)\n",
        "e20 = compute_err(X, y, 2,0.2)\n",
        "e35 = compute_err(X, y, 2,0.35)\n",
        "e50 = compute_err(X, y, 2,0.5)\n",
        "e65 = compute_err(X, y, 2,0.65)\n",
        "e80 = compute_err(X, y, 2,0.8)\n",
        "res = np.asarray(list((e20, e35, e50, e65, e80)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ft7N2eUTP6d6",
        "outputId": "8e57b021-834b-478f-8eee-6ca8e01f69bf"
      },
      "source": [
        "np.round(res.reshape((-1,5)).transpose(),3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.004, 0.005, 0.006, 0.008, 0.008],\n",
              "       [0.003, 0.004, 0.006, 0.007, 0.01 ],\n",
              "       [0.003, 0.004, 0.006, 0.008, 0.009],\n",
              "       [0.003, 0.004, 0.006, 0.007, 0.009],\n",
              "       [0.003, 0.004, 0.005, 0.007, 0.008]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vH2dbAHrQMj7",
        "outputId": "e8da77ba-0264-4a9e-bac0-b1e30bc799fa"
      },
      "source": [
        "np.round(e20,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.004],\n",
              "       [0.003],\n",
              "       [0.003],\n",
              "       [0.003],\n",
              "       [0.003]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGqInaaIIOOx"
      },
      "source": [
        "# seeds "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_klPa7GkW_5V"
      },
      "source": [
        "data = pd.read_table('https://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt',\n",
        "                     sep = '\\s+', header = None)\n",
        "data = pd.DataFrame.to_numpy(data)\n",
        "X,y = data[:,:7], data[:,7]-1 # reset the labels to go start from 0  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LKfen3IJsAH"
      },
      "source": [
        "G = 3\n",
        "np.random.seed(4)\n",
        "e20 = compute_err(X, y, G,0.2)\n",
        "e35 = compute_err(X, y, G,0.35)\n",
        "e50 = compute_err(X, y, G,0.5)\n",
        "e65 = compute_err(X, y, G,0.65)\n",
        "e80 = compute_err(X, y, G,0.8)\n",
        "res = np.asarray(list((e20, e35, e50, e65, e80)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BHbfyWexjan",
        "outputId": "447338e1-b26b-45a4-c665-1a5914ea4f89"
      },
      "source": [
        "np.round(res.reshape((-1,5)).transpose(),3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.004, 0.007, 0.009, 0.008, 0.014],\n",
              "       [0.003, 0.006, 0.013, 0.014, 0.034],\n",
              "       [0.005, 0.01 , 0.02 , 0.024, 0.033],\n",
              "       [0.005, 0.01 , 0.019, 0.023, 0.025],\n",
              "       [0.004, 0.008, 0.011, 0.016, 0.019]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAyThjRNQOgN",
        "outputId": "fb76a504-0ebc-4d9f-a156-e2514853c4f9"
      },
      "source": [
        "np.round(e20,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.004],\n",
              "       [0.003],\n",
              "       [0.005],\n",
              "       [0.005],\n",
              "       [0.004]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VB9LJW3IOPk"
      },
      "source": [
        "# wine\n",
        "The data set is also available in sklearn, as noted in the package's website. So, we load it directly from sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgmq0y4yIOPm"
      },
      "source": [
        "wine = datasets.load_wine()\n",
        "X,y = wine.data, wine.target.ravel() \n",
        "# sum(y==0), sum(y==1), sum(y==2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QzPNij2jmyD"
      },
      "source": [
        "G = 3\n",
        "np.random.seed(11) \n",
        "e20 = compute_err(X, y, G,0.2)\n",
        "e35 = compute_err(X, y, G,0.35)\n",
        "e50 = compute_err(X, y, G,0.5)\n",
        "e65 = compute_err(X, y, G,0.65)\n",
        "e80 = compute_err(X, y, G,0.8)\n",
        "res = np.asarray(list((e20, e35, e50, e65, e80)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imxK8tCDFGMU",
        "outputId": "bf8ebf8a-de3c-4f8a-f3ef-aaeca3f44d75"
      },
      "source": [
        "np.round(res.reshape((-1,5)).transpose(),3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.005, 0.006, 0.009, 0.009, 0.012],\n",
              "       [0.006, 0.009, 0.01 , 0.014, 0.021],\n",
              "       [0.007, 0.011, 0.016, 0.021, 0.025],\n",
              "       [0.007, 0.011, 0.015, 0.02 , 0.023],\n",
              "       [0.005, 0.007, 0.01 , 0.013, 0.017]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bw85S7ntQTfB",
        "outputId": "bb483028-e42c-4fb6-a72b-65083080e75c"
      },
      "source": [
        "np.round(e20,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.005],\n",
              "       [0.006],\n",
              "       [0.007],\n",
              "       [0.007],\n",
              "       [0.005]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JE_FulEEAamU"
      },
      "source": [
        "# Iris\n",
        "The data set is also available in sklearn, as noted in the package's website. So, we load it directly from sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtzYeUdYw4G6"
      },
      "source": [
        "iris = datasets.load_iris()\n",
        "X,y = iris.data, iris.target.ravel() \n",
        "G = 3\n",
        "np.random.seed(6)\n",
        "e20 = compute_err(X, y, G,0.2)\n",
        "e35 = compute_err(X, y, G,0.35)\n",
        "e50 = compute_err(X, y, G,0.5)\n",
        "e65 = compute_err(X, y, G,0.65)\n",
        "e80 = compute_err(X, y, G,0.8)\n",
        "res = np.asarray(list((e20, e35, e50, e65, e80)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-YSmMR1cYE2",
        "outputId": "04165747-5c26-4dca-c12b-65c6f589ea34"
      },
      "source": [
        "np.round(res.reshape((-1,5)).transpose(),3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.008, 0.01 , 0.012, 0.01 , 0.016],\n",
              "       [0.008, 0.018, 0.029, 0.03 , 0.049],\n",
              "       [0.014, 0.029, 0.043, 0.045, 0.069],\n",
              "       [0.014, 0.028, 0.04 , 0.042, 0.061],\n",
              "       [0.01 , 0.017, 0.021, 0.037, 0.042]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhJ_nFueQVRn",
        "outputId": "53d8ab32-8635-4d41-b5d1-f34c7aaf9480"
      },
      "source": [
        "np.round(e20,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.008],\n",
              "       [0.008],\n",
              "       [0.014],\n",
              "       [0.014],\n",
              "       [0.01 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    }
  ]
}