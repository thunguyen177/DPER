{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DPER without equal covariance assumption.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thunguyen177/DPER/blob/main/DPER_without_equal_covariance_assumption.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01Q1wGI3uIdg"
      },
      "source": [
        "## libraries and function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEdO9dJPION8",
        "outputId": "b80553f9-6f0e-43d8-a417-4bd2361c0df9"
      },
      "source": [
        "!pip install impyute\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as skLDA\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "import impyute as impy\n",
        "from fancyimpute import IterativeSVD, SoftImpute, NuclearNormMinimization\n",
        "import pandas as pd\n",
        "import time \n",
        "!pip install missingpy\n",
        "from missingpy import MissForest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting impyute\n",
            "  Downloading https://files.pythonhosted.org/packages/37/28/86829f67c9affb847facaab94687761d3555539ec675f7577778c5b2680a/impyute-0.0.8-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from impyute) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from impyute) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from impyute) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->impyute) (1.0.1)\n",
            "Installing collected packages: impyute\n",
            "Successfully installed impyute-0.0.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting missingpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/be/998d04d27054b58f0974b5f09f8457778a0a72d4355e0b7ae877b6cfb850/missingpy-0.2.0-py3-none-any.whl (49kB)\n",
            "\r\u001b[K     |██████▊                         | 10kB 16.3MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 20kB 21.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 30kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 40kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 4.5MB/s \n",
            "\u001b[?25hInstalling collected packages: missingpy\n",
            "Successfully installed missingpy-0.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6WJ1RH8pyXC"
      },
      "source": [
        "### MLE estimation function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiZ7C5gU2ywr"
      },
      "source": [
        "def diag_term(X,i):\n",
        "  arr0 = X[:,i].flatten()\n",
        "  arr = arr0[~np.isnan(arr0)]\n",
        "  return np.var(arr)\n",
        "\n",
        "def musMLE(X,y,G):\n",
        "    n,p = X.shape[0], X.shape[1]\n",
        "    f = lambda g: np.nanmean(X[y==g,:],axis=0)\n",
        "    musMLE = np.array([f(g) for g in range(G)])    \n",
        "    return musMLE.T\n",
        "\n",
        "def Smle(X,y,musMLE,g):\n",
        "    '''\n",
        "    function to compute the covariance matrix for the g-th class\n",
        "    X: input, should be a numpy array\n",
        "    y: label\n",
        "    G: number of classes\n",
        "    g: class index\n",
        "    output:\n",
        "    - mus: each row is a class mean\n",
        "    - S: common covariance matrix of class 1,2,..., G \n",
        "    '''\n",
        "    epsilon = 1e-5 # define epsilon to put r down to 0 if r < epsilon\n",
        "    Xg, yg = X[y==g,:], y[y==g]\n",
        "    n,p = Xg.shape[0], Xg.shape[1] \n",
        " \n",
        "    S = np.diag([diag_term(Xg,i) for i in range(p)]) \n",
        "\n",
        "    for i in range(p):      \n",
        "      for j in range(i):\n",
        "        if ((S[i,i] == 0.) | (S[j,j] == 0.)):\n",
        "          S[i,j] = S[j,i] = 0.\n",
        "          continue\n",
        "\n",
        "        mat = Xg[:,[i,j]]\n",
        "\n",
        "        # drop rows with NA\n",
        "        idx = ~np.isnan(mat).any(axis=1)\n",
        "        mat, y_arr = mat[idx], yg[idx]\n",
        "        A = mg = len(y_arr) \n",
        "\n",
        "        s11 = mg*np.var(mat[:,0])\n",
        "        s22 = mg*np.var(mat[:,1])\n",
        "        s12 = sum((mat[:,0]-musMLE[i,g])*(mat[:,1]-musMLE[j,g]))\n",
        "        B = S[i,i]*S[j,j]*A - s22 * S[i,i] - s11 * S[j,j]\n",
        "        coefficient = [-A, s12, B, s12*S[i,i]*S[j,j]]\n",
        "        r = np.roots(coefficient)\n",
        "        r = r[abs(np.imag(r)) < epsilon]\n",
        "        r = np.real(r)\n",
        "        r[abs(r) < epsilon] = 0\n",
        " \n",
        "        if len(r)>1:\n",
        "          condi_var = S[j,j] - r**2/S[i,i]\n",
        "          eta = -A*np.log(condi_var)-(S[j,j]-2*r/S[i,i]*s12 + r**2/S[i,i]**2*s11)/condi_var\n",
        "          r = r[eta == max(eta[~np.isnan(eta)])]\n",
        "\n",
        "        if len(r) > 1: \n",
        "          if sum(r==0.0) == len(r):\n",
        "            r = 0.\n",
        "          else:  \n",
        "            w = np.cov(mat, rowvar=False)  \n",
        "            #r = r[w[0,1]*r>=0]\n",
        "            r = r[np.abs(r-w[0,1]).argmin()] # select r that is closet to w[0,1] \n",
        "\n",
        "        S[i,j] = S[j,i] = r\n",
        "    return S"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwG2bsDOOxls"
      },
      "source": [
        "### compute_err function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEAkkeS5IOOo"
      },
      "source": [
        "def err(mus, S, mus_est, S_est):\n",
        "  er = [np.linalg.norm(mus_est-mus)/mus.size,\n",
        "        np.linalg.norm(S_est.flatten().flatten()-S.flatten())/S.size]  \n",
        "  return np.mean(er)  \n",
        "\n",
        "def generate_nan(Xtrain, missing_rate):\n",
        "  Xshape = Xtrain.shape\n",
        "  na_id = np.random.randint(0,Xtrain.size,round(missing_rate*Xtrain.size))\n",
        "  Xtr_nan = Xtrain.flatten()\n",
        "  Xtr_nan[na_id] = np.nan \n",
        "  return Xtr_nan.reshape(Xshape) \n",
        "\n",
        "def compute_err(Xtrain, ytrain, G, missing_rate):  \n",
        "    Xtr_nan = generate_nan(Xtrain, missing_rate)\n",
        "    \n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(Xtr_nan)\n",
        "    Xtr_nan = scaler.transform(Xtr_nan)\n",
        "    Xtrain = scaler.transform(Xtrain)\n",
        "    \n",
        "    # estimate parameters from full data\n",
        "    # each row is a mean of a class\n",
        "    mus = np.array([np.mean(Xtrain[ytrain==g,:], axis=0) for g in np.arange(G)])\n",
        "    S = np.array([np.cov(Xtrain[ytrain==g,:],rowvar =False) \n",
        "             for g in np.arange(G)])\n",
        "    print('original mus',mus)\n",
        "    print('S', S) \n",
        "\n",
        "    # MLEs approach\n",
        "    start = time.time()\n",
        "    mus_mle = musMLE(Xtr_nan,y,G)\n",
        "    S_mle = np.array([Smle(Xtr_nan,y,mus_mle, g) for g in range(G)])   \n",
        "    print('mus MLE',mus_mle)\n",
        "    print('S MLE', S_mle)          \n",
        "    mle_err = err(mus, S, mus_mle.T, S_mle)\n",
        "    mle_time = time.time()-start\n",
        "\n",
        "    start = time.time()\n",
        "    Xtr_softimpute = SoftImpute(max_iters = 100).fit_transform(Xtr_nan)\n",
        "    mus_softimpute = np.asarray([np.mean(Xtr_softimpute[ytrain==g,:], axis=0\n",
        "                                         ) for g in np.arange(G)])\n",
        "    S_softimpute = np.asarray([np.cov(Xtr_softimpute[ytrain==g,:], rowvar =False) \n",
        "             for g in np.arange(G)])\n",
        "\n",
        "    print('mus soft impute', mus_softimpute)\n",
        "    print('S soft impute', S_softimpute)\n",
        "    softimpute_err =  err(mus, S, mus_softimpute, S_softimpute)\n",
        "    softimpute_time = time.time()-start\n",
        "\n",
        "    start = time.time()\n",
        "    Xtr_mice = IterativeImputer(max_iter=100).fit(Xtr_nan).transform(Xtr_nan)\n",
        "    mus_mice = np.asarray([np.mean(Xtr_mice[ytrain==g,:], axis=0\n",
        "                                   ) for g in np.arange(G)])\n",
        "    S_mice = np.asarray([np.cov(Xtr_mice[ytrain==g,:], rowvar =False) \n",
        "             for g in np.arange(G)])\n",
        "\n",
        "    mice_err = err(mus, S, mus_mice, S_mice)\n",
        "    mice_time = time.time()-start\n",
        "\n",
        "    start = time.time()\n",
        "    Xtr_nuclear = NuclearNormMinimization(max_iters=100).fit_transform(Xtr_nan)\n",
        "    mus_nuclear = np.asarray([np.mean(Xtr_nuclear[ytrain==g,:], axis=0\n",
        "                                      ) for g in np.arange(G)])\n",
        "    S_nuclear = np.asarray([(sum(ytrain==g))*np.cov(Xtr_nuclear[ytrain==g,:], rowvar =False) \n",
        "             for g in np.arange(G)])\n",
        "    nuclear_err = err(mus, S, mus_nuclear, S_nuclear)\n",
        "    nuclear_time = time.time()-start\n",
        "    \n",
        "    start = time.time()\n",
        "    Xtr_mforest = MissForest(random_state=0).fit_transform(Xtr_nan)\n",
        "    mus_mforest = np.asarray([np.mean(Xtr_mforest[ytrain==g,:], axis=0\n",
        "                                      ) for g in np.arange(G)])\n",
        "    S_mforest = np.asarray([(sum(ytrain==g))*np.cov(Xtr_mforest[ytrain==g,:], rowvar =False) \n",
        "             for g in np.arange(G)])\n",
        "    mforest_err = err(mus, S, mus_mforest, S_mforest)\n",
        "    mforest_time = time.time()-start\n",
        "\n",
        "    err_rate = np.vstack((mle_err, mice_err, softimpute_err,nuclear_err, mforest_err))\n",
        "    return err_rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAz9dbKRRcRb"
      },
      "source": [
        "## Inosphere"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJBwudfzRoHp",
        "outputId": "b8d2d736-42c3-44d6-84f5-f36c5194e9f5"
      },
      "source": [
        "data = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data',\n",
        "                  sep = \",\", header = None)\n",
        "# print(data.head())\n",
        "data = pd.DataFrame.to_numpy(data)\n",
        "X, y = data[:,:34].astype(np.float64), data[:,34]\n",
        "le2 = LabelEncoder()\n",
        "y = le2.fit_transform(y)\n",
        "print(len(y))\n",
        "X = np.delete(X,[0,1], axis = 1)\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "351\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(351, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v351ig3rssOa"
      },
      "source": [
        "G = 2\n",
        "np.random.seed(3)\n",
        "e20 = compute_err(X, y, G,0.2)\n",
        "e35 = compute_err(X, y, G,0.35)\n",
        "e50 = compute_err(X, y, G,0.5)\n",
        "e65 = compute_err(X, y, G,0.65)\n",
        "e80 = compute_err(X, y, G,0.8)\n",
        "res = np.asarray(list((e20, e35, e50, e65, e80)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOlcDShstba4",
        "outputId": "661e364b-b545-47d6-a501-ec0ab8f34a91"
      },
      "source": [
        "np.round(res.reshape((-1,5)).transpose(),3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.003, 0.004, 0.006, 0.007, 0.008],\n",
              "       [0.004, 0.005, 0.005, 0.006, 0.01 ],\n",
              "       [0.003, 0.005, 0.005, 0.007, 0.009],\n",
              "       [0.67 , 0.615, 0.57 , 0.531, 0.511],\n",
              "       [0.717, 0.704, 0.693, 0.688, 0.682]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wsby2tbL-DC",
        "outputId": "efb4be33-5135-410d-e233-1d25eee6df1c"
      },
      "source": [
        "np.around(e20,3)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.003],\n",
              "       [0.004],\n",
              "       [0.003],\n",
              "       [0.67 ],\n",
              "       [0.717]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGqInaaIIOOx"
      },
      "source": [
        "# seeds "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_klPa7GkW_5V"
      },
      "source": [
        "data = pd.read_table('https://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt',\n",
        "                     sep = '\\s+', header = None)\n",
        "data = pd.DataFrame.to_numpy(data)\n",
        "X,y = data[:,:7], data[:,7]-1 # reset the labels to go start from 0  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LKfen3IJsAH"
      },
      "source": [
        "G = 3\n",
        "np.random.seed(3)\n",
        "e20 = compute_err(X, y, G,0.2)\n",
        "e35 = compute_err(X, y, G,0.35)\n",
        "e50 = compute_err(X, y, G,0.5)\n",
        "e65 = compute_err(X, y, G,0.65)\n",
        "e80 = compute_err(X, y, G,0.8)\n",
        "res = np.asarray(list((e20, e35, e50, e65, e80)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKmHpvEkv5GI",
        "outputId": "afb712c0-9d77-4bdb-b66a-62bceb49f282"
      },
      "source": [
        "np.round(res.reshape((-1,5)).transpose(),3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.004, 0.008, 0.007, 0.009, 0.009],\n",
              "       [0.004, 0.009, 0.01 , 0.017, 0.025],\n",
              "       [0.007, 0.015, 0.016, 0.025, 0.028],\n",
              "       [0.522, 0.517, 0.459, 0.489, 0.486],\n",
              "       [0.52 , 0.543, 0.504, 0.607, 0.647]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uuYz0ryMP1J",
        "outputId": "4a8b0320-60e1-44a4-f90c-09522d4ff11e"
      },
      "source": [
        "np.around(e20,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.004],\n",
              "       [0.004],\n",
              "       [0.007],\n",
              "       [0.522],\n",
              "       [0.52 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VB9LJW3IOPk"
      },
      "source": [
        "# wine\n",
        "The data set is also available in sklearn, as noted in the package's website. So, we load it directly from sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgmq0y4yIOPm"
      },
      "source": [
        "wine = datasets.load_wine()\n",
        "X,y = wine.data, wine.target.ravel() \n",
        "# sum(y==0), sum(y==1), sum(y==2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QzPNij2jmyD"
      },
      "source": [
        "G = 3\n",
        "np.random.seed(3)\n",
        "e20 = compute_err(X, y, G,0.2)\n",
        "e35 = compute_err(X, y, G,0.35)\n",
        "e50 = compute_err(X, y, G,0.5)\n",
        "e65 = compute_err(X, y, G,0.65)\n",
        "e80 = compute_err(X, y, G,0.8)\n",
        "res = np.asarray(list((e20, e35, e50, e65, e80)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5ASEk5vwgXY",
        "outputId": "ebed2edc-1060-4ce2-ad9b-709df6957e0e"
      },
      "source": [
        "np.round(res.reshape((-1,5)).transpose(),3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.005, 0.009, 0.008, 0.012, 0.013],\n",
              "       [0.005, 0.01 , 0.011, 0.014, 0.018],\n",
              "       [0.006, 0.012, 0.016, 0.023, 0.025],\n",
              "       [0.27 , 0.256, 0.239, 0.229, 0.215],\n",
              "       [0.288, 0.277, 0.276, 0.304, 0.286]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGGpulZYMR8h",
        "outputId": "7a438f79-ed26-45f3-ff82-43ebc0c988f9"
      },
      "source": [
        "np.around(e20,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.005],\n",
              "       [0.005],\n",
              "       [0.006],\n",
              "       [0.27 ],\n",
              "       [0.288]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JE_FulEEAamU"
      },
      "source": [
        "# Iris\n",
        "The data set is also available in sklearn, as noted in the package's website. So, we load it directly from sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtzYeUdYw4G6"
      },
      "source": [
        "iris = datasets.load_iris()\n",
        "X,y = iris.data, iris.target.ravel() \n",
        "G = 3\n",
        "np.random.seed(3)\n",
        "e20 = compute_err(X, y, G,0.2)\n",
        "e35 = compute_err(X, y, G,0.35)\n",
        "e50 = compute_err(X, y, G,0.5)\n",
        "e65 = compute_err(X, y, G,0.65)\n",
        "e80 = compute_err(X, y, G,0.8)\n",
        "res = np.asarray(list((e20, e35, e50, e65, e80)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHe2EoxTvmhH",
        "outputId": "f9f6e72d-31b0-47c1-c5b9-ab60502c3711"
      },
      "source": [
        "np.round(res.reshape((-1,5)).transpose(),3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.007, 0.009, 0.006, 0.013, 0.024],\n",
              "       [0.009, 0.015, 0.017, 0.033, 0.035],\n",
              "       [0.013, 0.025, 0.026, 0.049, 0.049],\n",
              "       [0.693, 0.665, 0.597, 0.672, 0.616],\n",
              "       [0.71 , 0.857, 0.812, 0.998, 0.951]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqngtHfkMWpX",
        "outputId": "9af1a720-7f5e-42dd-ac0e-abb98970dc70"
      },
      "source": [
        "np.around(e20,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.007],\n",
              "       [0.009],\n",
              "       [0.013],\n",
              "       [0.693],\n",
              "       [0.71 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}