{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DPER with equal covariance assumption_FASHION_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thunguyen177/DPER/blob/main/DPER_with_equal_covariance_assumption_FASHION_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01Q1wGI3uIdg"
      },
      "source": [
        "## libraries and function \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEdO9dJPION8"
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as skLDA\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "import impyute as impy\n",
        "from fancyimpute import SoftImpute, NuclearNormMinimization\n",
        "import pandas as pd\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm5CldkaaZWo"
      },
      "source": [
        "## MLE estimation function  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2pnqBY91dul"
      },
      "source": [
        "def diag_term(i,X,y):\n",
        "  arr0 = X[:,i]\n",
        "  nar2 = 0\n",
        "  arr = arr0[~np.isnan(arr0)]\n",
        "  y_arr = y[~np.isnan(arr0)]\n",
        "\n",
        "  _, counts = np.unique(y_arr, return_counts=True)\n",
        "  ind = np.insert(np.cumsum(counts), 0, 0)\n",
        "  \n",
        "  return sum([(ind[g]-ind[g-1])*np.var(arr[ind[g-1]:ind[g]]) for \n",
        "                       g in range(1,G+1)])/len(y_arr)                       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7A2gflMad84"
      },
      "source": [
        "def mle(X,y,G):\n",
        "    '''\n",
        "    X: input, should be a numpy array\n",
        "    y: label\n",
        "    G: number of classes\n",
        "    output:\n",
        "    - mus: each row is a class mean\n",
        "    - S: common covariance matrix of class 1,2,..., G \n",
        "    '''\n",
        "    epsilon = 1e-5 # define epsilon to put r down to 0 if r < epsilon\n",
        "    n,p = X.shape[0], X.shape[1]\n",
        "\n",
        "    mus = np.array([np.nanmean(X[y==g,:],axis=0) for g in range (G)]).T # so that each column is the mean of a class\n",
        " \n",
        "\n",
        "    S = np.diag([diag_term(i,X,y) for i in range(p)]) \n",
        "\n",
        "    for i in range(p):      \n",
        "      for j in range(i):\n",
        "        mat = X[:,[i,j]]\n",
        "\n",
        "        # drop rows with NA\n",
        "        idx = ~np.isnan(mat).any(axis=1)\n",
        "        mat, y_arr = mat[idx], y[idx]\n",
        "\n",
        "        _, counts = np.unique(y_arr, return_counts=True)\n",
        "        ind = np.insert(np.cumsum(counts), 0, 0)\n",
        "\n",
        "        m_g = counts\n",
        "        \n",
        "        A = len(y_arr)\n",
        "\n",
        "        scaled_mat = [mat[ind[g-1]:ind[g],:]-mus[[i,j],g-1] for g in range(1,G+1)]\n",
        "    \n",
        "        q = lambda g: np.dot(scaled_mat[g][:,0],scaled_mat[g][:,0])\n",
        "        s11 = sum(map(q,range(G))) \n",
        "        q = lambda g: np.dot(scaled_mat[g][:,1],scaled_mat[g][:,1])\n",
        "        s22 = sum(map(q,range(G))) \n",
        "        d = lambda g: np.dot(scaled_mat[g][:,0],scaled_mat[g][:,1])\n",
        "        s12 = sum(map(d,range(G)))  \n",
        "\n",
        "        start_solve = time.time()\n",
        "        B = S[i,i]*S[j,j]*A - s22 * S[i,i] - s11 * S[j,j]\n",
        "        coefficient = [-A, s12, B, s12*S[i,i]*S[j,j]]\n",
        "        r = np.roots(coefficient)\n",
        "\n",
        "        r = r[abs(np.imag(r)) < epsilon]\n",
        "        r = np.real(r)\n",
        "        r[abs(r) < epsilon] = 0\n",
        "\n",
        "        if len(r)>1:\n",
        "          condi_var = S[j,j] - r**2/S[i,i]\n",
        "          eta = -A*np.log(condi_var)-(S[j,j]-2*r/S[i,i]*s12 +\n",
        "                                      r**2/S[i,i]**2*s11)/condi_var\n",
        "          # if condi_var <0 then eta = NA. in practice, it's impossible for cov to be negative\n",
        "          #  therefore, we drop NA elements of eta  \n",
        "          r = r[eta == max(eta[~np.isnan(eta)])]\n",
        "\n",
        "        if len(r) > 1:        \n",
        "            w = [m_g[g-1]*np.cov(mat[ind[g-1]:ind[g],], rowvar=False) for\n",
        "                 g in range(1,G+1)]\n",
        "            w = np.sum(w, axis = 0)   \n",
        "            r = r[np.abs(r-w[0,1]).argmin()] # choose r that is w[0,1] \n",
        "              \n",
        "        S[i,j] = S[j,i] = r\n",
        "    return [mus, S]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwG2bsDOOxls"
      },
      "source": [
        "### compute_err function \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEAkkeS5IOOo"
      },
      "source": [
        "def err(mus, S, mus_est, S_est):\n",
        "  er = [np.linalg.norm(mus_est-mus)/mus.size,\n",
        "         np.linalg.norm(S_est.flatten()-S.flatten())/S.size]\n",
        "  return np.mean(er)  \n",
        "\n",
        "def generate_nan(Xtrain, missing_rate):\n",
        "  Xshape = Xtrain.shape\n",
        "  na_id = np.random.randint(0,Xtrain.size,round(missing_rate*Xtrain.size))\n",
        "  Xtr_nan = Xtrain.flatten()\n",
        "  Xtr_nan[na_id] = np.nan \n",
        "  return Xtr_nan.reshape(Xshape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xByWUzBf7OBY"
      },
      "source": [
        "### Algorithm to compute error for DPER only"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loi7W9arQjUC"
      },
      "source": [
        "def compute_err_mforest(Xtrain, ytrain, G, missing_rate):  \n",
        "    Xtr_nan = generate_nan(Xtrain, missing_rate)\n",
        "    \n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(Xtr_nan)\n",
        "    Xtr_nan = scaler.transform(Xtr_nan)\n",
        "    Xtrain = scaler.transform(Xtrain)\n",
        "    \n",
        "    # estimate parameters from full data\n",
        "    mus = [np.mean(Xtrain[ytrain==g,:], axis=0) for g in np.arange(G)]\n",
        "    mus = np.asarray(mus) # each row is a mean of a class\n",
        "    S = [sum(ytrain==g)*np.cov(Xtrain[ytrain==g,:],rowvar =False) \n",
        "             for g in np.arange(G)]\n",
        "    S = np.sum(S, axis = 0)/len(ytrain)\n",
        "\n",
        "    start = time.time()\n",
        "    Xtr_mforest = MissForest(random_state=0).fit_transform(Xtr_nan)\n",
        "    mus_mforest = np.asarray([np.mean(Xtr_mforest[ytrain==g,:], axis=0\n",
        "                                         ) for g in np.arange(G)])\n",
        "    S_mforest = np.asarray([(sum(ytrain==g))*np.cov(Xtr_mforest[ytrain==g,:], rowvar =False) \n",
        "             for g in np.arange(G)])\n",
        "    S_mforest = np.sum(S_mforest, axis = 0)/len(ytrain)   \n",
        "    mforest_err =  err(mus, S, mus_mforest, S_mforest)\n",
        "    mforest_time = time.time()-start   \n",
        "    return mforest_err, mforest_time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulsAXCTO7Vg0"
      },
      "source": [
        "def compute_err_dper(Xtrain, ytrain, G, missing_rate):  \n",
        "    Xtr_nan = generate_nan(Xtrain, missing_rate)\n",
        "    \n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(Xtr_nan)\n",
        "    Xtr_nan = scaler.transform(Xtr_nan)\n",
        "    Xtrain = scaler.transform(Xtrain)\n",
        "    \n",
        "    #Sort dataset by y_train\n",
        "    arsort = ytrain.argsort()\n",
        "    ytrain = ytrain[arsort]\n",
        "    Xtrain = Xtrain[arsort]\n",
        "    Xtr_nan = Xtr_nan[arsort]\n",
        "    \n",
        "    #Find indices\n",
        "    _, counts = np.unique(ytrain, return_counts=True)\n",
        "    ind = np.insert(np.cumsum(counts), 0, 0)\n",
        "\n",
        "    mus = np.array([np.mean(Xtrain[ind[g-1]:ind[g]],axis=0) for g in range(1,G+1)])\n",
        "    S = [(ind[g]-ind[g-1])*np.cov(Xtrain[ind[g-1]:ind[g],:],rowvar = False) for g in range(1,G+1)]\n",
        "    S = np.sum(S, axis = 0)/len(ytrain)\n",
        "\n",
        "    # MLEs approach\n",
        "    start = time.time()\n",
        "    mus_mle, S_mle = mle(Xtr_nan,ytrain, G)\n",
        "    mle_err = err(mus, S, mus_mle.T, S_mle)\n",
        "    mle_time = time.time()-start     \n",
        "    return mle_err, mle_time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85Kfd2egBi7f"
      },
      "source": [
        "def compute_err_soft(Xtrain, ytrain, G, missing_rate):  \n",
        "    Xtr_nan = generate_nan(Xtrain, missing_rate)\n",
        "    \n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(Xtr_nan)\n",
        "    Xtr_nan = scaler.transform(Xtr_nan)\n",
        "    Xtrain = scaler.transform(Xtrain)\n",
        "    \n",
        "    # estimate parameters from full data\n",
        "    mus = [np.mean(Xtrain[ytrain==g,:], axis=0) for g in np.arange(G)]\n",
        "    mus = np.asarray(mus) # each row is a mean of a class\n",
        "    S = [sum(ytrain==g)*np.cov(Xtrain[ytrain==g,:],rowvar =False) \n",
        "             for g in np.arange(G)]\n",
        "    S = np.sum(S, axis = 0)/len(ytrain)\n",
        "\n",
        "    start = time.time()\n",
        "    Xtr_softimpute = SoftImpute(max_iters = 100).fit_transform(Xtr_nan)\n",
        "    mus_softimpute = np.asarray([np.mean(Xtr_softimpute[ytrain==g,:], axis=0\n",
        "                                         ) for g in np.arange(G)])\n",
        "    S_softimpute = np.asarray([(sum(ytrain==g))*np.cov(Xtr_softimpute[ytrain==g,:], rowvar =False) \n",
        "             for g in np.arange(G)])\n",
        "    S_softimpute = np.sum(S_softimpute, axis = 0)/len(ytrain)   \n",
        "    softimpute_err =  err(mus, S, mus_softimpute, S_softimpute)\n",
        "    softimpute_time = time.time()-start   \n",
        "    return softimpute_err, softimpute_time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oiq2g4u5GzD-"
      },
      "source": [
        "def compute_err_mice(Xtrain, ytrain, G, missing_rate):  \n",
        "    Xtr_nan = generate_nan(Xtrain, missing_rate)\n",
        "    \n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(Xtr_nan)\n",
        "    Xtr_nan = scaler.transform(Xtr_nan)\n",
        "    Xtrain = scaler.transform(Xtrain)\n",
        "    \n",
        "    # estimate parameters from full data\n",
        "    mus = [np.mean(Xtrain[ytrain==g,:], axis=0) for g in np.arange(G)]\n",
        "    mus = np.asarray(mus) # each row is a mean of a class\n",
        "    S = [sum(ytrain==g)*np.cov(Xtrain[ytrain==g,:],rowvar =False) \n",
        "             for g in np.arange(G)]\n",
        "    S = np.sum(S, axis = 0)/len(ytrain)\n",
        "\n",
        "    start = time.time()\n",
        "    Xtr_mice = IterativeImputer(max_iter=10).fit(Xtr_nan).transform(Xtr_nan)\n",
        "    mus_mice = np.asarray([np.mean(Xtr_mice[ytrain==g,:], axis=0\n",
        "                                   ) for g in np.arange(G)])\n",
        "    S_mice = np.asarray([(sum(ytrain==g))*np.cov(Xtr_mice[ytrain==g,:], rowvar =False) \n",
        "             for g in np.arange(G)])\n",
        "    S_mice = np.sum(S_mice, axis = 0)/len(ytrain)\n",
        "    mice_err = err(mus, S, mus_mice, S_mice)\n",
        "    mice_time = time.time()-start\n",
        "\n",
        "    return mice_err, mice_time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05V293yIoD9H"
      },
      "source": [
        "def compute_err_nuclear(Xtrain, ytrain, G, missing_rate):  \n",
        "    Xtr_nan = generate_nan(Xtrain, missing_rate)\n",
        "    \n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(Xtr_nan)\n",
        "    Xtr_nan = scaler.transform(Xtr_nan)\n",
        "    Xtrain = scaler.transform(Xtrain)\n",
        "    \n",
        "    # estimate parameters from full data\n",
        "    mus = [np.mean(Xtrain[ytrain==g,:], axis=0) for g in np.arange(G)]\n",
        "    mus = np.asarray(mus) # each row is a mean of a class\n",
        "    S = [sum(ytrain==g)*np.cov(Xtrain[ytrain==g,:],rowvar =False) \n",
        "             for g in np.arange(G)]\n",
        "    S = np.sum(S, axis = 0)/len(ytrain)\n",
        "\n",
        "    start = time.time()\n",
        "    Xtr_nuclear = NuclearNormMinimization(max_iters=10).fit_transform(Xtr_nan)\n",
        "    mus_nuclear = np.asarray([np.mean(Xtr_nuclear[ytrain==g,:], axis=0\n",
        "                                      ) for g in np.arange(G)])\n",
        "    S_nuclear = np.asarray([(sum(ytrain==g))*np.cov(Xtr_nuclear[ytrain==g,:], rowvar =False) \n",
        "             for g in np.arange(G)])\n",
        "    S_nuclear = np.sum(S_nuclear, axis = 0)/len(ytrain)\n",
        "    nuclear_err = err(mus, S, mus_nuclear, S_nuclear)\n",
        "    nuclear_time = time.time()-start\n",
        "\n",
        "    return nuclear_err, nuclear_time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xsJ_-uc61V6"
      },
      "source": [
        "# FASHION MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5jXMk4w64g3"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(Xtrain, ytrain), (Xtest, ytest) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVra6Qm17GrY",
        "outputId": "0f015cd0-0c66-4917-f639-b5328d3f474c"
      },
      "source": [
        "Xtrain = Xtrain.astype(float).reshape((60000,784))\n",
        "Xtest = Xtest.astype(float).reshape((10000,784))\n",
        "\n",
        "X = np.vstack((Xtrain, Xtest))\n",
        "y = np.hstack((ytrain, ytest))\n",
        "\n",
        "# set random seed and shuffle the data\n",
        "np.random.seed(1)\n",
        "idx = np.arange(len(y))\n",
        "np.random.shuffle(idx)\n",
        "X, y = X[idx,:], y[idx]  \n",
        "\n",
        "X.shape, y.shape "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((70000, 784), (70000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVmXRgPs7auE",
        "outputId": "b21e269b-22f6-4353-aabe-6e130859796f"
      },
      "source": [
        "# check if a column is all 0\n",
        "id = [np.sum(Xtrain[:,i] != 0)>10 for i in range(28**2)]\n",
        "# number of columns that mostly zero\n",
        "print(28**2-np.sum(id))\n",
        "# number of columns that has at least more than 10 non-zero\n",
        "np.sum(id)\n",
        "X = X[:, id]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SefvzC3WSLrM"
      },
      "source": [
        "## Mforest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avBkZl7WQjUG"
      },
      "source": [
        "# run 6 hours giving no result\n",
        "G = 10\n",
        "e20_mforest = compute_err_mforest(X, y, G, 0.2)\n",
        "e20_mforest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykZ7KZ8NS-It"
      },
      "source": [
        "e35_mforest = compute_err_mforest(X, y, G, 0.35)\n",
        "e50_mforest = compute_err_mforest(X, y, G, 0.5)\n",
        "e65_mforest = compute_err_mforest(X, y, G, 0.65)\n",
        "e80_mforest = compute_err_mforest(X, y, G, 0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uphxKDKZqiCb"
      },
      "source": [
        "## DPER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlONbQSa7lXN",
        "outputId": "42bc9ffc-213a-4c63-b8b9-27c385144b73"
      },
      "source": [
        "G = 10\n",
        "e20_dper = compute_err_dper(X, y, G, 0.2)\n",
        "e35_dper = compute_err_dper(X, y, G, 0.35)\n",
        "e50_dper = compute_err_dper(X, y, G, 0.5)\n",
        "e65_dper = compute_err_dper(X, y, G, 0.65)\n",
        "e80_dper = compute_err_dper(X, y, G, 0.8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "computation time 1906.490648984909\n",
            "computation time 1611.3365874290466\n",
            "computation time 1387.5780763626099\n",
            "computation time 1170.8552837371826\n",
            "computation time 1039.692412853241\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKriCp_gvP1X",
        "outputId": "35cb2a4f-e3e0-4833-996b-c66872143edb"
      },
      "source": [
        "# the left column is the error, the right column is the running time\n",
        "np.vstack((e20_dper,e35_dper,e50_dper,e65_dper,e80_dper))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.92527404e-05, 1.90649065e+03],\n",
              "       [3.89047417e-05, 1.61133659e+03],\n",
              "       [4.91157708e-05, 1.38757808e+03],\n",
              "       [5.82590926e-05, 1.17085528e+03],\n",
              "       [7.32972844e-05, 1.03969241e+03]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDwhQvu3qbq7"
      },
      "source": [
        "## Soft impute"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiuVnH_Cqm3D"
      },
      "source": [
        "e20_soft = compute_err_soft(X, y, G, 0.2)\n",
        "e35_soft = compute_err_soft(X, y, G, 0.35)\n",
        "e50_soft = compute_err_soft(X, y, G, 0.5)\n",
        "e65_soft = compute_err_soft(X, y, G, 0.65)\n",
        "e80_soft = compute_err_soft(X, y, G, 0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-cSjaEqQjUH",
        "outputId": "9fd20931-4475-481c-d634-3332ef0c9ee4"
      },
      "source": [
        "# the left column is the error, the right column is the running time\n",
        "np.vstack((e20_soft, e35_soft,e50_soft,e65_soft,e80_soft))\n",
        "np.round(np.vstack((e20_soft, e35_soft,e50_soft,e65_soft,e80_soft))[0],3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.89397495e-05, 1.02333118e+03],\n",
              "       [6.64847559e-05, 1.31015335e+03],\n",
              "       [9.57025225e-05, 1.74412689e+03],\n",
              "       [1.30314425e-04, 2.28746755e+03],\n",
              "       [1.69178211e-04, 2.65371597e+03]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgqSNrcfrNHg"
      },
      "source": [
        "## MICE impute"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHcJ1tClQjUI"
      },
      "source": [
        "e20_mice = compute_err_mice(X, y, G, 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q-W2C4drk7S",
        "scrolled": true
      },
      "source": [
        "e20_mice"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8q7EYWVTrUpk"
      },
      "source": [
        "e35_mice = compute_err_mice(X, y, G, 0.35)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2K-cJthrjLS"
      },
      "source": [
        "e35_mice"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSlRNwedrUZv"
      },
      "source": [
        "e50_mice = compute_err_mice(X, y, G, 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYiX_UosrihE"
      },
      "source": [
        "e50_mice"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnbW-V8MrUHw"
      },
      "source": [
        "e65_mice = compute_err_mice(X, y, G, 0.65)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHUYtiIFrg_9"
      },
      "source": [
        "e65_mice"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH486ls_JCN0"
      },
      "source": [
        "e80_mice = compute_err_mice(X, y, G, 0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYEL6nsMJG1j"
      },
      "source": [
        "e80_mice"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GUlQfcWrnKS"
      },
      "source": [
        "## Nuclear "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA3CcDaDQjUK"
      },
      "source": [
        "#kernel dies\n",
        "e20_nuclear = compute_err_nuclear(X, y, G, 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H51dCe9sAyS"
      },
      "source": [
        "e20_nuclear"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXzDx1JBrrOy"
      },
      "source": [
        "e35_nuclear = compute_err_nuclear(X, y, G, 0.35)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxCcYbM6r_cF"
      },
      "source": [
        "e35_nuclear"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtkXcw5LrrCB"
      },
      "source": [
        "e50_nuclear = compute_err_nuclear(X, y, G, 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FP9kWDq0r-zj"
      },
      "source": [
        "e50_nuclear"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FStzIBqrqzf"
      },
      "source": [
        "e65_nuclear = compute_err_nuclear(X, y, G, 0.65)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc8KVmq4r9ZX"
      },
      "source": [
        "e65_nuclear"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVTKZDwxrqg-"
      },
      "source": [
        "e80_nuclear = compute_err_nuclear(X, y, G, 0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfcVrefYoxnq"
      },
      "source": [
        "e80_nuclear"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}